{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPKPrDWNuvF2Q2ZfgTsM5cx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ljkrajewski/FramePack-Colab/blob/main/FramePack-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
        "!git clone https://github.com/ljkrajewski/FramePack-Colab.git\n",
        "%cd FramePack-Colab\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "ez800gMt6mWO",
        "outputId": "98a1ef7a-86f4-4ef5-972c-3497ddfabf6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu126/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu126/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n",
            "Cloning into 'FramePack-Colab'...\n",
            "remote: Enumerating objects: 99, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 99 (delta 32), reused 22 (delta 22), pack-reused 42 (from 2)\u001b[K\n",
            "Receiving objects: 100% (99/99), 55.12 KiB | 18.37 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n",
            "/content/FramePack-Colab\n",
            "Collecting accelerate==1.6.0 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting diffusers==0.33.1 (from -r requirements.txt (line 2))\n",
            "  Downloading diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting transformers==4.46.2 (from -r requirements.txt (line 3))\n",
            "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==5.23.0 (from -r requirements.txt (line 4))\n",
            "  Downloading gradio-5.23.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting sentencepiece==0.2.0 (from -r requirements.txt (line 5))\n",
            "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting pillow==11.1.0 (from -r requirements.txt (line 6))\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting av==12.1.0 (from -r requirements.txt (line 7))\n",
            "  Downloading av-12.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting numpy==1.26.2 (from -r requirements.txt (line 8))\n",
            "  Downloading numpy-1.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.12.0 (from -r requirements.txt (line 9))\n",
            "  Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.31.0 (from -r requirements.txt (line 10))\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting torchsde==0.2.6 (from -r requirements.txt (line 11))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.8.1)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (4.12.0.88)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (0.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0->-r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0->-r requirements.txt (line 1)) (0.34.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.1->-r requirements.txt (line 2)) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.1->-r requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers==0.33.1->-r requirements.txt (line 2)) (2024.11.6)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers==4.46.2->-r requirements.txt (line 3))\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.46.2->-r requirements.txt (line 3)) (4.67.1)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==5.23.0->-r requirements.txt (line 4))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (4.10.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (0.6.1)\n",
            "Collecting gradio-client==1.8.0 (from gradio==5.23.0->-r requirements.txt (line 4))\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (3.11.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (0.12.8)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.23.0->-r requirements.txt (line 4)) (0.35.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->-r requirements.txt (line 10)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->-r requirements.txt (line 10)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->-r requirements.txt (line 10)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests==2.31.0->-r requirements.txt (line 10)) (2025.8.3)\n",
            "Collecting trampoline>=0.1.2 (from torchsde==0.2.6->-r requirements.txt (line 11))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio==5.23.0->-r requirements.txt (line 4)) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio==5.23.0->-r requirements.txt (line 4)) (15.0.1)\n",
            "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-contrib-python (from -r requirements.txt (line 14))\n",
            "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.23.0->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.23.0->-r requirements.txt (line 4)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.23.0->-r requirements.txt (line 4)) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate==1.6.0->-r requirements.txt (line 1)) (1.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.23.0->-r requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.23.0->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.23.0->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==5.23.0->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==5.23.0->-r requirements.txt (line 4)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==5.23.0->-r requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.23.0->-r requirements.txt (line 4)) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.23.0->-r requirements.txt (line 4)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.23.0->-r requirements.txt (line 4)) (13.9.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers==0.33.1->-r requirements.txt (line 2)) (3.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio==5.23.0->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.23.0->-r requirements.txt (line 4)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.23.0->-r requirements.txt (line 4)) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==5.23.0->-r requirements.txt (line 4)) (0.1.2)\n",
            "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.23.0-py3-none-any.whl (51.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-12.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: trampoline, sentencepiece, requests, pillow, numpy, av, aiofiles, scipy, opencv-contrib-python, tokenizers, gradio-client, diffusers, transformers, torchsde, gradio, accelerate\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.1\n",
            "    Uninstalling sentencepiece-0.2.1:\n",
            "      Successfully uninstalled sentencepiece-0.2.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: aiofiles\n",
            "    Found existing installation: aiofiles 24.1.0\n",
            "    Uninstalling aiofiles-24.1.0:\n",
            "      Successfully uninstalled aiofiles-24.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.1\n",
            "    Uninstalling scipy-1.16.1:\n",
            "      Successfully uninstalled scipy-1.16.1\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.12.0.88\n",
            "    Uninstalling opencv-contrib-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-contrib-python-4.12.0.88\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.4\n",
            "    Uninstalling tokenizers-0.21.4:\n",
            "      Successfully uninstalled tokenizers-0.21.4\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.11.1\n",
            "    Uninstalling gradio_client-1.11.1:\n",
            "      Successfully uninstalled gradio_client-1.11.1\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.34.0\n",
            "    Uninstalling diffusers-0.34.0:\n",
            "      Successfully uninstalled diffusers-0.34.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.55.1\n",
            "    Uninstalling transformers-4.55.1:\n",
            "      Successfully uninstalled transformers-4.55.1\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.42.0\n",
            "    Uninstalling gradio-5.42.0:\n",
            "      Successfully uninstalled gradio-5.42.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.10.0\n",
            "    Uninstalling accelerate-1.10.0:\n",
            "      Successfully uninstalled accelerate-1.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.2 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.2 which is incompatible.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.31.0 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.2 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-1.6.0 aiofiles-23.2.1 av-12.1.0 diffusers-0.33.1 gradio-5.23.0 gradio-client-1.8.0 numpy-1.26.2 opencv-contrib-python-4.11.0.86 pillow-11.1.0 requests-2.31.0 scipy-1.12.0 sentencepiece-0.2.0 tokenizers-0.20.3 torchsde-0.2.6 trampoline-0.1.2 transformers-4.46.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "numpy"
                ]
              },
              "id": "119d9ba07e234ea997d8974d8b937bb1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## When the notebook \"crashes,\" restart with the next cell."
      ],
      "metadata": {
        "id": "1N6jW9JmQlaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/FramePack-colab\n",
        "!python demo_gradio.py --share"
      ],
      "metadata": {
        "id": "UiEPNcci7VuM",
        "outputId": "e1ce5c08-b767-4f35-fd3a-da3b243fbb8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/FramePack'\n",
            "/content/FramePack-Colab\n",
            "2025-08-16 02:15:45.879561: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-08-16 02:15:45.895342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755310545.916101    8001 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755310545.922558    8001 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755310545.939042    8001 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755310545.939067    8001 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755310545.939070    8001 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755310545.939073    8001 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-08-16 02:15:45.943943: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Currently enabled native sdp backends: ['flash', 'math', 'mem_efficient', 'cudnn']\n",
            "Xformers is not installed!\n",
            "Flash Attn is not installed!\n",
            "Sage Attn is not installed!\n",
            "Namespace(share=True, server='0.0.0.0', port=None, inbrowser=False)\n",
            "Free VRAM 21.9759521484375 GB\n",
            "High-VRAM Mode: False\n",
            "config.json: 100% 766/766 [00:00<00:00, 5.00MB/s]\n",
            "model.safetensors.index.json: 22.2kB [00:00, 76.1MB/s]\n",
            "Downloading shards:   0% 0/4 [00:00<?, ?it/s]\n",
            "text_encoder/model-00001-of-00004.safete(…):   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):   0% 590k/4.98G [00:02<5:30:36, 251kB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):   4% 202M/4.98G [00:02<00:52, 91.5MB/s] \u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):   7% 336M/4.98G [00:03<00:29, 159MB/s] \u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):   8% 403M/4.98G [00:03<00:33, 138MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  11% 537M/4.98G [00:04<00:24, 178MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  12% 604M/4.98G [00:04<00:27, 158MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  14% 673M/4.98G [00:07<00:58, 73.7MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  16% 807M/4.98G [00:07<00:34, 120MB/s] \u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  19% 943M/4.98G [00:07<00:23, 173MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  20% 1.01G/4.98G [00:07<00:22, 176MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  22% 1.08G/4.98G [00:08<00:22, 174MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  23% 1.14G/4.98G [00:08<00:23, 166MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  24% 1.21G/4.98G [00:11<00:55, 68.0MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  28% 1.41G/4.98G [00:11<00:25, 138MB/s] \u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  31% 1.55G/4.98G [00:11<00:18, 182MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  32% 1.61G/4.98G [00:12<00:20, 164MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  34% 1.68G/4.98G [00:12<00:20, 159MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  35% 1.75G/4.98G [00:13<00:20, 157MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  36% 1.81G/4.98G [00:15<00:46, 68.4MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  39% 1.95G/4.98G [00:16<00:28, 107MB/s] \u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  45% 2.22G/4.98G [00:16<00:13, 206MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  46% 2.29G/4.98G [00:17<00:14, 180MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  47% 2.35G/4.98G [00:17<00:14, 181MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  49% 2.42G/4.98G [00:18<00:21, 117MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  50% 2.49G/4.98G [00:19<00:26, 92.5MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  54% 2.69G/4.98G [00:20<00:13, 174MB/s] \u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  55% 2.76G/4.98G [00:20<00:11, 195MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  57% 2.82G/4.98G [00:20<00:11, 192MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  58% 2.89G/4.98G [00:21<00:10, 191MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  59% 2.96G/4.98G [00:21<00:10, 190MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  61% 3.02G/4.98G [00:21<00:12, 161MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  62% 3.09G/4.98G [00:23<00:17, 107MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  63% 3.16G/4.98G [00:24<00:19, 93.8MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  66% 3.29G/4.98G [00:24<00:10, 156MB/s] \u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  67% 3.36G/4.98G [00:24<00:11, 139MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  69% 3.43G/4.98G [00:25<00:10, 149MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  70% 3.49G/4.98G [00:25<00:08, 177MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  72% 3.57G/4.98G [00:25<00:07, 191MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  73% 3.64G/4.98G [00:28<00:18, 74.3MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  77% 3.84G/4.98G [00:28<00:07, 154MB/s] \u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  78% 3.91G/4.98G [00:28<00:06, 175MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  80% 3.97G/4.98G [00:28<00:06, 157MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  81% 4.04G/4.98G [00:29<00:06, 139MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  82% 4.11G/4.98G [00:30<00:06, 140MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  84% 4.17G/4.98G [00:30<00:04, 162MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  85% 4.24G/4.98G [00:30<00:03, 202MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  87% 4.31G/4.98G [00:30<00:03, 183MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  88% 4.37G/4.98G [00:31<00:02, 208MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  89% 4.44G/4.98G [00:31<00:02, 231MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  91% 4.51G/4.98G [00:31<00:01, 244MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  92% 4.57G/4.98G [00:31<00:01, 261MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  93% 4.64G/4.98G [00:32<00:01, 271MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  95% 4.71G/4.98G [00:32<00:01, 261MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  96% 4.78G/4.98G [00:32<00:00, 289MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  97% 4.84G/4.98G [00:32<00:00, 293MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…):  99% 4.91G/4.98G [00:32<00:00, 295MB/s]\u001b[A\n",
            "text_encoder/model-00001-of-00004.safete(…): 100% 4.98G/4.98G [00:33<00:00, 150MB/s]\n",
            "Downloading shards:  25% 1/4 [00:33<01:41, 33.69s/it]\n",
            "text_encoder/model-00002-of-00004.safete(…):   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):   0% 846k/5.00G [00:02<3:32:31, 392kB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):   3% 135M/5.00G [00:03<01:26, 56.0MB/s] \u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):   5% 269M/5.00G [00:03<00:46, 101MB/s] \u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):   7% 338M/5.00G [00:04<00:44, 105MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):   9% 472M/5.00G [00:04<00:28, 157MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  11% 539M/5.00G [00:05<00:34, 131MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  12% 609M/5.00G [00:05<00:34, 129MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  14% 676M/5.00G [00:06<00:38, 112MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  15% 743M/5.00G [00:07<00:36, 118MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  16% 810M/5.00G [00:07<00:29, 140MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  18% 877M/5.00G [00:07<00:24, 169MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  19% 944M/5.00G [00:10<00:58, 68.9MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  23% 1.15G/5.00G [00:10<00:26, 144MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  24% 1.21G/5.00G [00:10<00:23, 165MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  26% 1.28G/5.00G [00:10<00:21, 175MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  27% 1.34G/5.00G [00:11<00:21, 173MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  28% 1.41G/5.00G [00:11<00:22, 159MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  30% 1.48G/5.00G [00:11<00:20, 175MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  31% 1.55G/5.00G [00:14<00:48, 71.9MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  34% 1.68G/5.00G [00:15<00:40, 82.9MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  40% 2.02G/5.00G [00:15<00:16, 185MB/s] \u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  42% 2.09G/5.00G [00:16<00:16, 179MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  43% 2.15G/5.00G [00:16<00:17, 167MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  44% 2.22G/5.00G [00:17<00:16, 167MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  46% 2.29G/5.00G [00:17<00:16, 160MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  47% 2.35G/5.00G [00:18<00:18, 144MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  48% 2.42G/5.00G [00:18<00:18, 143MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  50% 2.49G/5.00G [00:19<00:17, 142MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  51% 2.56G/5.00G [00:19<00:17, 139MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  52% 2.62G/5.00G [00:20<00:18, 127MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  54% 2.69G/5.00G [00:21<00:19, 117MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  55% 2.76G/5.00G [00:21<00:16, 134MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  56% 2.82G/5.00G [00:26<01:00, 36.0MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  58% 2.89G/5.00G [00:29<01:07, 31.4MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  60% 3.02G/5.00G [00:29<00:34, 56.7MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  63% 3.16G/5.00G [00:30<00:22, 83.4MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  65% 3.23G/5.00G [00:39<01:11, 24.9MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  65% 3.26G/5.00G [00:45<01:38, 17.6MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  67% 3.33G/5.00G [00:45<01:11, 23.2MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  68% 3.40G/5.00G [00:45<00:50, 31.5MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  69% 3.46G/5.00G [00:45<00:36, 42.4MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  71% 3.53G/5.00G [00:46<00:25, 56.7MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  75% 3.73G/5.00G [00:46<00:12, 103MB/s] \u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  76% 3.80G/5.00G [00:47<00:10, 111MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  77% 3.86G/5.00G [00:47<00:10, 113MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  79% 3.93G/5.00G [00:49<00:14, 75.7MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  83% 4.13G/5.00G [00:49<00:05, 149MB/s] \u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  87% 4.33G/5.00G [00:49<00:02, 240MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  89% 4.46G/5.00G [00:50<00:02, 252MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  92% 4.60G/5.00G [00:50<00:01, 265MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  93% 4.66G/5.00G [00:50<00:01, 273MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  95% 4.73G/5.00G [00:51<00:00, 274MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  96% 4.80G/5.00G [00:51<00:00, 275MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…):  97% 4.87G/5.00G [00:51<00:00, 250MB/s]\u001b[A\n",
            "text_encoder/model-00002-of-00004.safete(…): 100% 5.00G/5.00G [00:52<00:00, 95.9MB/s]\n",
            "Downloading shards:  50% 2/4 [01:26<01:29, 44.81s/it]\n",
            "text_encoder/model-00003-of-00004.safete(…):   0% 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):   0% 691k/4.92G [00:04<9:44:10, 140kB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):   4% 202M/4.92G [00:05<01:35, 49.5MB/s] \u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):   8% 403M/4.92G [00:11<01:51, 40.5MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  11% 537M/4.92G [00:11<01:10, 61.7MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  14% 671M/4.92G [00:13<01:05, 64.7MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  15% 738M/4.92G [00:15<01:19, 52.2MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  18% 874M/4.92G [00:15<00:51, 78.5MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  19% 941M/4.92G [00:15<00:42, 92.7MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  21% 1.01G/4.92G [00:16<00:36, 107MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  22% 1.08G/4.92G [00:16<00:30, 126MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  23% 1.14G/4.92G [00:16<00:25, 146MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  25% 1.21G/4.92G [00:16<00:21, 175MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  27% 1.34G/4.92G [00:17<00:15, 233MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  29% 1.41G/4.92G [00:17<00:15, 225MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  31% 1.54G/4.92G [00:17<00:12, 277MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  33% 1.61G/4.92G [00:21<00:48, 67.5MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  34% 1.68G/4.92G [00:22<00:47, 67.7MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  36% 1.75G/4.92G [00:22<00:37, 84.8MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  37% 1.81G/4.92G [00:22<00:29, 105MB/s] \u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  38% 1.88G/4.92G [00:23<00:24, 122MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  40% 1.95G/4.92G [00:23<00:20, 146MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  41% 2.01G/4.92G [00:23<00:15, 189MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  42% 2.08G/4.92G [00:23<00:15, 180MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  44% 2.15G/4.92G [00:24<00:21, 128MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  45% 2.22G/4.92G [00:25<00:20, 130MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  46% 2.28G/4.92G [00:25<00:17, 151MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  48% 2.35G/4.92G [00:25<00:13, 192MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  49% 2.42G/4.92G [00:25<00:11, 217MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  51% 2.49G/4.92G [00:26<00:10, 238MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  52% 2.55G/4.92G [00:26<00:09, 254MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  53% 2.62G/4.92G [00:26<00:08, 269MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  55% 2.69G/4.92G [00:26<00:08, 278MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  56% 2.75G/4.92G [00:26<00:07, 287MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  57% 2.82G/4.92G [00:27<00:07, 296MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  59% 2.89G/4.92G [00:27<00:06, 300MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  60% 2.95G/4.92G [00:27<00:06, 298MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  61% 3.02G/4.92G [00:27<00:06, 291MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  63% 3.09G/4.92G [00:28<00:06, 288MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  64% 3.16G/4.92G [00:28<00:06, 285MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  66% 3.22G/4.92G [00:28<00:05, 283MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  67% 3.29G/4.92G [00:28<00:05, 282MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  68% 3.36G/4.92G [00:29<00:05, 280MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  70% 3.42G/4.92G [00:29<00:05, 280MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  71% 3.49G/4.92G [00:31<00:19, 73.0MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  72% 3.56G/4.92G [00:32<00:17, 78.1MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  74% 3.62G/4.92G [00:32<00:13, 98.2MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  76% 3.76G/4.92G [00:39<00:31, 37.1MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  78% 3.82G/4.92G [00:39<00:24, 44.8MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  79% 3.89G/4.92G [00:39<00:17, 57.6MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  81% 3.96G/4.92G [00:39<00:12, 76.7MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  83% 4.09G/4.92G [00:40<00:06, 127MB/s] \u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  85% 4.16G/4.92G [00:40<00:04, 154MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  86% 4.22G/4.92G [00:40<00:03, 182MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  87% 4.29G/4.92G [00:40<00:03, 204MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  89% 4.36G/4.92G [00:40<00:02, 208MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  90% 4.43G/4.92G [00:41<00:01, 248MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  91% 4.50G/4.92G [00:41<00:01, 270MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  93% 4.56G/4.92G [00:41<00:01, 264MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  95% 4.65G/4.92G [00:41<00:00, 291MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  96% 4.71G/4.92G [00:41<00:00, 312MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  97% 4.78G/4.92G [00:42<00:00, 227MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…):  99% 4.85G/4.92G [00:42<00:00, 215MB/s]\u001b[A\n",
            "text_encoder/model-00003-of-00004.safete(…): 100% 4.92G/4.92G [00:43<00:00, 114MB/s]\n",
            "Downloading shards:  75% 3/4 [02:09<00:44, 44.26s/it]\n",
            "text_encoder/model-00004-of-00004.safete(…):   0% 0.00/117M [00:00<?, ?B/s]\u001b[A\n",
            "text_encoder/model-00004-of-00004.safete(…): 100% 117M/117M [00:01<00:00, 70.8MB/s] \n",
            "Downloading shards: 100% 4/4 [02:12<00:00, 33.01s/it]\n",
            "Loading checkpoint shards: 100% 4/4 [00:01<00:00,  2.91it/s]\n",
            "config.json: 100% 646/646 [00:00<00:00, 5.68MB/s]\n",
            "text_encoder_2/model.safetensors: 100% 246M/246M [00:01<00:00, 141MB/s] \n",
            "tokenizer_config.json: 51.7kB [00:00, 118MB/s]\n",
            "tokenizer/tokenizer.json: 100% 17.2M/17.2M [00:01<00:00, 14.5MB/s]\n",
            "special_tokens_map.json: 100% 577/577 [00:00<00:00, 5.59MB/s]\n",
            "tokenizer_config.json: 100% 736/736 [00:00<00:00, 6.53MB/s]\n",
            "vocab.json: 1.06MB [00:00, 117MB/s]\n",
            "merges.txt: 525kB [00:00, 117MB/s]\n",
            "special_tokens_map.json: 100% 588/588 [00:00<00:00, 5.10MB/s]\n",
            "config.json: 100% 718/718 [00:00<00:00, 6.11MB/s]\n",
            "vae/diffusion_pytorch_model.safetensors: 100% 986M/986M [00:09<00:00, 104MB/s]\n",
            "preprocessor_config.json: 100% 394/394 [00:00<00:00, 3.08MB/s]\n",
            "config.json: 100% 585/585 [00:00<00:00, 4.82MB/s]\n",
            "model.safetensors: 100% 857M/857M [00:01<00:00, 430MB/s]\n",
            "config.json: 100% 658/658 [00:00<00:00, 6.12MB/s]\n",
            "(…)ion_pytorch_model.safetensors.index.json: 134kB [00:00, 184MB/s]\n",
            "Fetching 3 files:   0% 0/3 [00:00<?, ?it/s]\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   0% 0.00/5.79G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   0% 0.00/9.99G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   0% 21.0M/5.79G [00:00<00:42, 136MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   0% 10.5M/9.99G [00:00<01:39, 101MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   1% 41.9M/5.79G [00:00<00:34, 169MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   0% 0.00/9.97G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   0% 41.9M/9.99G [00:00<00:46, 213MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   2% 94.4M/5.79G [00:00<00:19, 292MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   0% 21.0M/9.97G [00:00<01:09, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   1% 73.4M/9.99G [00:00<00:39, 254MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   2% 136M/5.79G [00:00<00:17, 323MB/s] \u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   1% 52.4M/9.97G [00:00<00:47, 207MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   1% 115M/9.99G [00:00<00:33, 292MB/s] \u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   3% 178M/5.79G [00:00<00:17, 320MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   1% 94.4M/9.97G [00:00<00:34, 283MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   2% 157M/9.99G [00:00<00:30, 321MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   1% 136M/9.97G [00:00<00:30, 324MB/s] \u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   4% 220M/5.79G [00:00<00:17, 320MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   2% 199M/9.99G [00:00<00:28, 349MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   2% 241M/9.99G [00:00<00:27, 351MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   2% 178M/9.97G [00:00<00:31, 315MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   5% 262M/5.79G [00:00<00:17, 307MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   3% 283M/9.99G [00:00<00:32, 294MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   2% 220M/9.97G [00:00<00:36, 268MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   5% 304M/5.79G [00:01<00:20, 270MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   3% 315M/9.99G [00:01<00:37, 258MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   3% 252M/9.97G [00:01<00:47, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   6% 336M/5.79G [00:01<00:28, 193MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   3% 346M/9.99G [00:01<00:43, 220MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   3% 283M/9.97G [00:01<00:46, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   6% 367M/5.79G [00:01<00:25, 215MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   4% 377M/9.99G [00:01<00:43, 222MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   3% 315M/9.97G [00:01<00:46, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   7% 398M/5.79G [00:01<00:25, 209MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   4% 409M/9.99G [00:01<00:42, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   3% 346M/9.97G [00:01<00:43, 222MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   7% 430M/5.79G [00:01<00:23, 226MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   4% 440M/9.99G [00:01<00:39, 242MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   4% 388M/9.97G [00:01<00:38, 252MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   8% 472M/5.79G [00:01<00:20, 256MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   5% 472M/9.99G [00:01<00:37, 255MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   4% 419M/9.97G [00:01<00:46, 204MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   9% 503M/5.79G [00:02<00:27, 193MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   5% 503M/9.99G [00:02<00:49, 190MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   5% 451M/9.97G [00:02<00:56, 168MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   9% 535M/5.79G [00:02<00:33, 155MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   5% 535M/9.99G [00:02<01:02, 151MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   5% 472M/9.97G [00:02<01:05, 145MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  10% 556M/5.79G [00:04<02:22, 36.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   6% 556M/9.99G [00:04<04:25, 35.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   5% 493M/9.97G [00:04<04:34, 34.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  10% 598M/5.79G [00:04<01:33, 55.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   6% 587M/9.99G [00:04<03:10, 49.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   5% 524M/9.97G [00:04<03:13, 48.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  11% 640M/5.79G [00:04<01:05, 78.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   6% 629M/9.99G [00:04<02:08, 72.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   6% 566M/9.97G [00:04<02:08, 73.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  12% 682M/5.79G [00:05<00:48, 106MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   7% 671M/9.99G [00:04<01:31, 101MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   6% 608M/9.97G [00:04<01:31, 103MB/s] \u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  12% 724M/5.79G [00:05<00:36, 139MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   7% 713M/9.99G [00:05<01:09, 134MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   7% 650M/9.97G [00:04<01:08, 137MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   7% 744M/9.99G [00:05<01:02, 149MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  13% 765M/5.79G [00:05<00:32, 155MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   7% 682M/9.97G [00:05<01:04, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   8% 776M/9.99G [00:05<01:06, 138MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  14% 797M/5.79G [00:05<00:34, 144MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   7% 713M/9.97G [00:05<01:08, 135MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   8% 807M/9.99G [00:05<01:12, 127MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  14% 828M/5.79G [00:05<00:37, 131MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   7% 744M/9.97G [00:05<01:14, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   8% 828M/9.99G [00:05<01:13, 124MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  15% 849M/5.79G [00:06<00:38, 128MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   8% 765M/9.97G [00:05<01:15, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   9% 849M/9.99G [00:06<01:14, 123MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  15% 870M/5.79G [00:06<00:39, 125MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   8% 786M/9.97G [00:06<01:15, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   9% 870M/9.99G [00:06<01:09, 131MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  15% 891M/5.79G [00:06<00:37, 132MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   8% 807M/9.97G [00:06<01:09, 132MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   9% 891M/9.99G [00:06<01:02, 145MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  16% 912M/5.79G [00:06<00:33, 146MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   8% 839M/9.97G [00:06<00:56, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   9% 923M/9.99G [00:06<00:51, 174MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  16% 954M/5.79G [00:06<00:25, 191MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   9% 881M/9.97G [00:06<00:44, 203MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  10% 965M/9.99G [00:06<00:41, 216MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  17% 996M/5.79G [00:06<00:22, 213MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   9% 912M/9.97G [00:06<00:45, 201MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  10% 996M/9.99G [00:06<00:54, 165MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  18% 1.03G/5.79G [00:07<00:28, 165MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   9% 944M/9.97G [00:06<00:56, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  10% 1.02G/9.99G [00:07<01:01, 145MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  18% 1.05G/5.79G [00:07<00:31, 149MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  10% 965M/9.97G [00:07<01:03, 141MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  10% 1.04G/9.99G [00:07<01:06, 134MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  18% 1.07G/5.79G [00:07<00:34, 137MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  10% 986M/9.97G [00:07<01:09, 130MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  11% 1.06G/9.99G [00:07<01:14, 120MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  19% 1.09G/5.79G [00:07<00:37, 127MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  10% 1.01G/9.97G [00:07<01:12, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  11% 1.08G/9.99G [00:07<01:14, 120MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  19% 1.11G/5.79G [00:07<00:39, 119MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  10% 1.03G/9.97G [00:07<01:15, 119MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  11% 1.10G/9.99G [00:07<01:21, 109MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  20% 1.13G/5.79G [00:08<00:40, 114MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  11% 1.05G/9.97G [00:07<01:21, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  11% 1.12G/9.99G [00:08<01:18, 113MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  20% 1.15G/5.79G [00:08<00:40, 113MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  11% 1.07G/9.97G [00:08<01:21, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  11% 1.14G/9.99G [00:08<01:18, 113MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  20% 1.17G/5.79G [00:08<00:40, 114MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  11% 1.09G/9.97G [00:08<01:24, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  12% 1.16G/9.99G [00:08<01:21, 109MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  21% 1.20G/5.79G [00:08<00:40, 112MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  11% 1.11G/9.97G [00:08<01:24, 104MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  12% 1.18G/9.99G [00:08<01:23, 105MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  21% 1.22G/5.79G [00:08<00:42, 107MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  11% 1.13G/9.97G [00:08<01:24, 104MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  12% 1.21G/9.99G [00:08<01:22, 107MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  21% 1.24G/5.79G [00:09<00:42, 107MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  12% 1.15G/9.97G [00:08<01:23, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  12% 1.23G/9.99G [00:09<01:22, 107MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  22% 1.26G/5.79G [00:09<00:42, 106MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  12% 1.17G/9.97G [00:09<01:23, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  12% 1.25G/9.99G [00:09<01:22, 105MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  22% 1.28G/5.79G [00:09<00:43, 104MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  12% 1.20G/9.97G [00:09<01:21, 107MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  13% 1.27G/9.99G [00:09<01:24, 103MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  22% 1.30G/5.79G [00:09<00:42, 106MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  12% 1.22G/9.97G [00:09<01:23, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  13% 1.29G/9.99G [00:09<01:23, 104MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  23% 1.32G/5.79G [00:09<00:42, 104MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  12% 1.24G/9.97G [00:09<01:26, 101MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  13% 1.31G/9.99G [00:09<01:21, 107MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  23% 1.34G/5.79G [00:10<00:41, 107MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  13% 1.26G/9.97G [00:09<01:22, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  13% 1.33G/9.99G [00:10<01:20, 108MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  13% 1.28G/9.97G [00:10<01:20, 108MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  24% 1.36G/5.79G [00:10<00:49, 89.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.35G/9.99G [00:10<01:19, 109MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  24% 1.38G/5.79G [00:10<00:44, 99.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  13% 1.30G/9.97G [00:10<01:21, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.37G/9.99G [00:10<01:20, 107MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  24% 1.41G/5.79G [00:10<00:43, 101MB/s] \u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  13% 1.32G/9.97G [00:10<01:21, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.39G/9.99G [00:10<01:20, 107MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  25% 1.43G/5.79G [00:10<00:44, 99.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  13% 1.34G/9.97G [00:10<01:24, 103MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.42G/9.99G [00:10<01:26, 98.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  25% 1.44G/5.79G [00:11<00:45, 95.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.35G/9.97G [00:10<01:27, 98.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.43G/9.99G [00:11<01:29, 95.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  25% 1.45G/5.79G [00:11<00:46, 92.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.36G/9.97G [00:10<01:31, 94.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.44G/9.99G [00:11<01:32, 92.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  25% 1.46G/5.79G [00:11<00:48, 89.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.37G/9.97G [00:11<01:35, 89.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.45G/9.99G [00:11<01:38, 86.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  25% 1.47G/5.79G [00:11<00:52, 82.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.38G/9.97G [00:11<01:44, 82.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.46G/9.99G [00:11<01:45, 80.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  26% 1.48G/5.79G [00:11<00:54, 79.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.39G/9.97G [00:11<01:47, 79.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.47G/9.99G [00:11<01:49, 77.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  26% 1.49G/5.79G [00:11<00:56, 76.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.41G/9.97G [00:11<01:51, 76.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.48G/9.99G [00:11<01:50, 77.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  26% 1.50G/5.79G [00:11<00:56, 75.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.42G/9.97G [00:11<01:52, 75.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.49G/9.99G [00:11<01:53, 75.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  26% 1.51G/5.79G [00:12<00:57, 74.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.43G/9.97G [00:11<01:53, 75.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.50G/9.99G [00:12<01:53, 74.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  26% 1.52G/5.79G [00:12<00:59, 71.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.44G/9.97G [00:11<01:58, 72.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.51G/9.99G [00:12<01:58, 71.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  26% 1.53G/5.79G [00:12<01:00, 70.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.45G/9.97G [00:12<02:01, 70.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.52G/9.99G [00:12<02:00, 70.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  27% 1.54G/5.79G [00:12<01:02, 68.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.46G/9.97G [00:12<02:04, 68.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.53G/9.99G [00:12<02:03, 68.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  27% 1.55G/5.79G [00:12<01:02, 67.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.47G/9.97G [00:12<02:05, 67.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.54G/9.99G [00:12<02:04, 67.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.48G/9.97G [00:12<01:59, 70.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  27% 1.56G/5.79G [00:12<01:02, 68.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  16% 1.56G/9.99G [00:12<01:26, 97.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.52G/9.97G [00:12<00:59, 142MB/s] \u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  28% 1.60G/5.79G [00:12<00:30, 136MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  16% 1.59G/9.99G [00:12<00:57, 146MB/s] \u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  28% 1.64G/5.79G [00:13<00:23, 174MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  16% 1.56G/9.97G [00:12<00:42, 196MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  16% 1.64G/9.99G [00:13<00:41, 199MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  29% 1.67G/5.79G [00:13<00:23, 176MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  16% 1.59G/9.97G [00:13<00:43, 191MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  17% 1.67G/9.99G [00:13<00:49, 170MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  29% 1.69G/5.79G [00:13<00:28, 145MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  16% 1.61G/9.97G [00:13<00:54, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  17% 1.69G/9.99G [00:13<00:54, 151MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  30% 1.71G/5.79G [00:13<00:30, 135MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  16% 1.64G/9.97G [00:13<00:59, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  17% 1.71G/9.99G [00:13<01:02, 132MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  30% 1.73G/5.79G [00:13<00:32, 124MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  17% 1.66G/9.97G [00:13<01:05, 127MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  17% 1.73G/9.99G [00:13<01:04, 129MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  30% 1.75G/5.79G [00:14<00:33, 119MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  17% 1.68G/9.97G [00:13<01:08, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.75G/9.99G [00:14<01:08, 120MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  31% 1.77G/5.79G [00:14<00:35, 113MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  17% 1.70G/9.97G [00:14<01:12, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.77G/9.99G [00:14<01:09, 119MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  31% 1.79G/5.79G [00:14<00:35, 112MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  17% 1.72G/9.97G [00:14<01:13, 113MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.79G/9.99G [00:14<01:14, 110MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  31% 1.81G/5.79G [00:14<00:37, 106MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  17% 1.74G/9.97G [00:14<01:17, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.81G/9.99G [00:14<01:17, 106MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  32% 1.84G/5.79G [00:14<00:39, 100MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.76G/9.97G [00:14<01:20, 102MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.84G/9.99G [00:14<01:18, 104MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  32% 1.85G/5.79G [00:15<00:39, 98.6MB/s]\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  32% 1.86G/5.79G [00:15<00:41, 94.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.78G/9.97G [00:14<01:28, 92.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.86G/9.99G [00:15<01:36, 84.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  32% 1.87G/5.79G [00:15<00:50, 78.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.79G/9.97G [00:15<01:43, 78.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.87G/9.99G [00:15<01:46, 76.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  32% 1.88G/5.79G [00:15<01:02, 62.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.80G/9.97G [00:15<02:07, 64.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.88G/9.99G [00:15<02:10, 62.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  33% 1.89G/5.79G [00:15<01:07, 57.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.81G/9.97G [00:15<02:18, 58.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.89G/9.99G [00:15<02:21, 57.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  33% 1.90G/5.79G [00:16<01:21, 47.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.82G/9.97G [00:16<02:45, 49.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  33% 1.91G/5.79G [00:16<01:32, 42.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.90G/9.99G [00:16<03:26, 39.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.91G/9.99G [00:16<03:00, 44.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  33% 1.92G/5.79G [00:16<01:33, 41.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.84G/9.97G [00:16<03:47, 35.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.92G/9.99G [00:16<03:08, 42.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  33% 1.93G/5.79G [00:17<01:36, 40.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  19% 1.86G/9.97G [00:16<02:56, 45.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.94G/9.99G [00:17<02:07, 63.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  34% 1.97G/5.79G [00:17<00:41, 91.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  19% 1.90G/9.97G [00:16<01:30, 88.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  20% 1.99G/9.99G [00:17<01:02, 128MB/s] \u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  35% 2.01G/5.79G [00:17<00:27, 137MB/s] \u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  19% 1.94G/9.97G [00:17<01:02, 130MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  20% 2.01G/9.99G [00:17<01:02, 129MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  35% 2.03G/5.79G [00:17<00:28, 134MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  20% 1.96G/9.97G [00:17<01:02, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  20% 2.03G/9.99G [00:17<01:08, 116MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  35% 2.06G/5.79G [00:17<00:30, 123MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  20% 1.98G/9.97G [00:17<01:06, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  21% 2.06G/9.99G [00:17<01:10, 112MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  36% 2.08G/5.79G [00:17<00:31, 117MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  20% 2.00G/9.97G [00:17<01:09, 115MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  21% 2.08G/9.99G [00:17<01:06, 119MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  36% 2.10G/5.79G [00:18<00:30, 123MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  20% 2.02G/9.97G [00:17<01:05, 121MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  21% 2.10G/9.99G [00:18<01:03, 124MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  37% 2.12G/5.79G [00:18<00:28, 127MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  21% 2.04G/9.97G [00:17<01:02, 126MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  21% 2.12G/9.99G [00:18<00:57, 136MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  37% 2.14G/5.79G [00:18<00:26, 140MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  21% 2.07G/9.97G [00:18<00:57, 138MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  37% 2.16G/5.79G [00:18<00:25, 141MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  21% 2.09G/9.97G [00:18<00:57, 138MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  22% 2.15G/9.99G [00:21<05:05, 25.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  38% 2.18G/5.79G [00:24<05:19, 11.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  21% 2.11G/9.97G [00:24<11:33, 11.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  22% 2.17G/9.99G [00:24<09:11, 14.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  38% 2.22G/5.79G [00:24<02:55, 20.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  22% 2.21G/9.99G [00:24<05:20, 24.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  21% 2.14G/9.97G [00:24<07:18, 17.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  39% 2.26G/5.79G [00:24<01:48, 32.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  23% 2.25G/9.99G [00:24<03:25, 37.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  22% 2.18G/9.97G [00:24<04:20, 29.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  40% 2.31G/5.79G [00:24<01:12, 48.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  23% 2.30G/9.99G [00:24<02:20, 54.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  22% 2.22G/9.97G [00:24<02:49, 45.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  41% 2.35G/5.79G [00:24<00:49, 69.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  23% 2.34G/9.99G [00:24<01:40, 76.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  23% 2.26G/9.97G [00:24<01:58, 65.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  41% 2.39G/5.79G [00:24<00:36, 94.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  24% 2.37G/9.99G [00:24<01:20, 94.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  23% 2.30G/9.97G [00:24<01:32, 82.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  42% 2.43G/5.79G [00:25<00:27, 124MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  24% 2.42G/9.99G [00:25<00:57, 131MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  23% 2.33G/9.97G [00:24<01:17, 99.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  43% 2.47G/5.79G [00:25<00:29, 114MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  25% 2.45G/9.99G [00:25<01:06, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  24% 2.36G/9.97G [00:25<01:22, 92.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  43% 2.51G/5.79G [00:25<00:25, 127MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  24% 2.40G/9.97G [00:25<00:59, 127MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  25% 2.49G/9.99G [00:25<00:58, 128MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  44% 2.55G/5.79G [00:25<00:20, 160MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  25% 2.44G/9.97G [00:25<00:46, 162MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  25% 2.52G/9.99G [00:25<00:49, 152MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  45% 2.58G/5.79G [00:25<00:17, 183MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  25% 2.49G/9.97G [00:25<00:39, 189MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  26% 2.56G/9.99G [00:25<00:40, 185MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  45% 2.61G/5.79G [00:25<00:15, 201MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  25% 2.52G/9.97G [00:25<00:36, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  26% 2.59G/9.99G [00:26<00:38, 191MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  46% 2.64G/5.79G [00:26<00:16, 192MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  26% 2.55G/9.97G [00:26<00:43, 169MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  26% 2.62G/9.99G [00:26<00:47, 155MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  46% 2.67G/5.79G [00:26<00:19, 157MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  26% 2.64G/9.99G [00:26<00:52, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  26% 2.58G/9.97G [00:26<00:52, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  47% 2.69G/5.79G [00:26<00:21, 141MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  26% 2.60G/9.97G [00:26<00:52, 141MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  47% 2.72G/5.79G [00:26<00:22, 138MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  27% 2.66G/9.99G [00:26<01:02, 118MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  47% 2.74G/5.79G [00:26<00:22, 135MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  27% 2.68G/9.99G [00:26<00:58, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  26% 2.62G/9.97G [00:26<01:04, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  48% 2.76G/5.79G [00:27<00:23, 131MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  27% 2.71G/9.99G [00:27<01:00, 120MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  26% 2.64G/9.97G [00:27<01:07, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  48% 2.78G/5.79G [00:27<00:25, 119MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  27% 2.73G/9.99G [00:27<01:02, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  27% 2.66G/9.97G [00:27<01:04, 113MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  48% 2.80G/5.79G [00:27<00:26, 113MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  28% 2.75G/9.99G [00:27<01:03, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  27% 2.68G/9.97G [00:27<01:06, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  49% 2.82G/5.79G [00:27<00:26, 112MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  28% 2.77G/9.99G [00:27<01:05, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  27% 2.71G/9.97G [00:27<01:09, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  28% 2.79G/9.99G [00:27<01:08, 106MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  49% 2.84G/5.79G [00:28<00:29, 98.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  27% 2.73G/9.97G [00:27<01:14, 97.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  49% 2.85G/5.79G [00:28<00:31, 94.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  28% 2.81G/9.99G [00:28<01:10, 102MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.75G/9.97G [00:28<01:06, 109MB/s] \u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  50% 2.87G/5.79G [00:28<00:26, 109MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  28% 2.83G/9.99G [00:28<01:04, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.77G/9.97G [00:28<01:06, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  50% 2.89G/5.79G [00:28<00:26, 108MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  29% 2.85G/9.99G [00:28<01:06, 108MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.79G/9.97G [00:28<01:07, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  50% 2.92G/5.79G [00:28<00:26, 107MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  29% 2.87G/9.99G [00:28<01:06, 107MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.81G/9.97G [00:28<01:06, 107MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  51% 2.94G/5.79G [00:28<00:26, 106MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  29% 2.89G/9.99G [00:28<01:07, 104MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.83G/9.97G [00:28<01:09, 102MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  51% 2.96G/5.79G [00:29<00:27, 103MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  29% 2.92G/9.99G [00:29<01:11, 98.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  51% 2.97G/5.79G [00:29<00:28, 98.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.85G/9.97G [00:29<01:08, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  29% 2.94G/9.99G [00:29<01:05, 107MB/s] \u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  52% 2.99G/5.79G [00:29<00:26, 104MB/s] \u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.87G/9.97G [00:29<01:09, 103MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  52% 3.00G/5.79G [00:29<00:27, 102MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.88G/9.97G [00:29<01:10, 101MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 2.96G/9.99G [00:29<01:09, 102MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  52% 3.01G/5.79G [00:29<00:29, 95.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.89G/9.97G [00:29<01:22, 85.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 2.97G/9.99G [00:29<01:21, 86.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  52% 3.02G/5.79G [00:29<00:36, 75.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.90G/9.97G [00:29<01:29, 78.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 2.98G/9.99G [00:29<01:26, 81.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  52% 3.03G/5.79G [00:30<00:35, 76.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.92G/9.97G [00:29<01:28, 79.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 2.99G/9.99G [00:30<01:26, 81.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  53% 3.04G/5.79G [00:30<00:35, 77.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.93G/9.97G [00:30<01:30, 78.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 3.00G/9.99G [00:30<01:27, 79.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  53% 3.05G/5.79G [00:30<00:36, 74.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.94G/9.97G [00:30<01:33, 75.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 3.01G/9.99G [00:30<01:31, 76.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  53% 3.06G/5.79G [00:30<00:35, 75.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 2.95G/9.97G [00:30<01:32, 76.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 3.02G/9.99G [00:30<01:30, 76.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  53% 3.07G/5.79G [00:30<00:36, 74.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 2.96G/9.97G [00:30<01:42, 68.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 3.03G/9.99G [00:30<01:41, 68.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  53% 3.08G/5.79G [00:30<00:42, 64.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 2.97G/9.97G [00:30<01:44, 67.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 3.04G/9.99G [00:30<01:41, 68.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  53% 3.09G/5.79G [00:30<00:38, 69.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 2.98G/9.97G [00:30<01:38, 70.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  31% 3.05G/9.99G [00:30<01:36, 71.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  54% 3.10G/5.79G [00:31<00:36, 72.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 2.99G/9.97G [00:30<01:30, 77.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  31% 3.06G/9.99G [00:31<01:29, 77.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  54% 3.11G/5.79G [00:31<00:33, 79.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 3.00G/9.97G [00:30<01:23, 83.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  31% 3.08G/9.99G [00:31<01:17, 88.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  54% 3.14G/5.79G [00:31<00:29, 89.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 3.02G/9.97G [00:31<01:15, 92.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  31% 3.10G/9.99G [00:31<01:06, 103MB/s] \u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  55% 3.16G/5.79G [00:31<00:24, 109MB/s] \u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  31% 3.05G/9.97G [00:31<00:50, 138MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  31% 3.14G/9.99G [00:31<00:46, 149MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  55% 3.20G/5.79G [00:31<00:15, 170MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  31% 3.09G/9.97G [00:31<00:35, 193MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  32% 3.18G/9.99G [00:31<00:33, 204MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  56% 3.23G/5.79G [00:31<00:12, 203MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  31% 3.12G/9.97G [00:31<00:34, 200MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  32% 3.21G/9.99G [00:31<00:43, 156MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  56% 3.26G/5.79G [00:32<00:16, 157MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  32% 3.15G/9.97G [00:31<00:45, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  32% 3.23G/9.99G [00:32<00:46, 144MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  57% 3.28G/5.79G [00:32<00:17, 144MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  32% 3.17G/9.97G [00:32<00:48, 141MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  33% 3.25G/9.99G [00:32<00:50, 132MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  57% 3.30G/5.79G [00:32<00:19, 129MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  32% 3.19G/9.97G [00:32<00:53, 126MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  33% 3.27G/9.99G [00:32<00:53, 126MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  57% 3.32G/5.79G [00:32<00:20, 121MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  32% 3.21G/9.97G [00:32<00:57, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  33% 3.29G/9.99G [00:32<00:57, 117MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  58% 3.34G/5.79G [00:32<00:21, 112MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  32% 3.23G/9.97G [00:32<00:57, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  33% 3.31G/9.99G [00:32<01:03, 106MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  58% 3.37G/5.79G [00:33<00:22, 107MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  33% 3.25G/9.97G [00:32<01:01, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  33% 3.33G/9.99G [00:33<01:03, 105MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  58% 3.39G/5.79G [00:33<00:23, 103MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  33% 3.27G/9.97G [00:33<01:06, 101MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  34% 3.36G/9.99G [00:33<01:07, 98.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  59% 3.41G/5.79G [00:33<00:24, 97.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  33% 3.29G/9.97G [00:33<01:12, 92.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  34% 3.37G/9.99G [00:33<01:10, 94.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  59% 3.42G/5.79G [00:33<00:25, 91.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  34% 3.38G/9.99G [00:33<01:13, 90.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  33% 3.30G/9.97G [00:33<01:18, 84.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  59% 3.43G/5.79G [00:33<00:27, 86.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  33% 3.31G/9.97G [00:33<01:22, 80.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  34% 3.39G/9.99G [00:33<01:25, 77.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  59% 3.44G/5.79G [00:34<00:30, 78.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  33% 3.32G/9.97G [00:33<01:23, 79.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  34% 3.41G/9.99G [00:33<01:06, 98.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  60% 3.46G/5.79G [00:34<00:22, 102MB/s] \u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  34% 3.36G/9.97G [00:33<00:54, 122MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  34% 3.44G/9.99G [00:34<00:47, 139MB/s] \u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  60% 3.49G/5.79G [00:34<00:15, 145MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  34% 3.38G/9.97G [00:34<00:50, 130MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  35% 3.46G/9.99G [00:34<00:49, 131MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  61% 3.51G/5.79G [00:34<00:17, 128MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  34% 3.40G/9.97G [00:34<00:57, 115MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  35% 3.48G/9.99G [00:34<00:57, 114MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  61% 3.53G/5.79G [00:34<00:18, 119MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  34% 3.42G/9.97G [00:34<01:01, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  61% 3.55G/5.79G [00:34<00:19, 114MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  35% 3.50G/9.99G [00:34<00:59, 108MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  34% 3.44G/9.97G [00:34<00:58, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  35% 3.52G/9.99G [00:34<00:54, 119MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  62% 3.58G/5.79G [00:34<00:18, 122MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  35% 3.46G/9.97G [00:34<01:01, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  35% 3.54G/9.99G [00:35<00:57, 111MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  62% 3.60G/5.79G [00:35<00:19, 114MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  36% 3.57G/9.99G [00:35<00:58, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  35% 3.48G/9.97G [00:35<01:04, 101MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  62% 3.62G/5.79G [00:35<00:19, 109MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  36% 3.59G/9.99G [00:35<00:57, 112MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  35% 3.50G/9.97G [00:35<01:03, 102MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  63% 3.64G/5.79G [00:35<00:27, 79.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  35% 3.51G/9.97G [00:36<02:21, 45.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  63% 3.65G/5.79G [00:36<01:00, 35.6MB/s]\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  63% 3.66G/5.79G [00:37<01:17, 27.4MB/s]\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  64% 3.72G/5.79G [00:37<00:29, 69.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  36% 3.61G/9.99G [00:37<04:05, 26.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  35% 3.52G/9.97G [00:37<04:47, 22.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  65% 3.76G/5.79G [00:37<00:20, 98.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  36% 3.55G/9.97G [00:37<02:43, 39.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  37% 3.65G/9.99G [00:37<02:19, 45.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  66% 3.81G/5.79G [00:37<00:15, 131MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  37% 3.68G/9.99G [00:37<01:39, 63.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  36% 3.60G/9.97G [00:37<01:34, 67.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  37% 3.73G/9.99G [00:38<01:01, 102MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  37% 3.65G/9.97G [00:37<00:57, 111MB/s] \u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  66% 3.84G/5.79G [00:38<00:15, 126MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  38% 3.79G/9.99G [00:38<00:42, 148MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  37% 3.70G/9.97G [00:38<00:41, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  67% 3.87G/5.79G [00:38<00:15, 124MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  37% 3.73G/9.97G [00:38<00:45, 138MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  38% 3.83G/9.99G [00:38<00:45, 135MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  67% 3.89G/5.79G [00:38<00:15, 120MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  38% 3.76G/9.97G [00:38<00:48, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  68% 3.91G/5.79G [00:38<00:16, 116MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  39% 3.86G/9.99G [00:38<00:48, 127MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  38% 3.79G/9.97G [00:38<00:52, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  68% 3.93G/5.79G [00:39<00:16, 109MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  39% 3.89G/9.99G [00:39<00:51, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  38% 3.81G/9.97G [00:39<00:51, 119MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  68% 3.95G/5.79G [00:39<00:16, 113MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  39% 3.91G/9.99G [00:39<00:50, 120MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  38% 3.83G/9.97G [00:39<00:49, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  69% 3.97G/5.79G [00:39<00:15, 118MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  39% 3.93G/9.99G [00:39<00:49, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  39% 3.85G/9.97G [00:39<00:49, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  69% 4.00G/5.79G [00:39<00:15, 116MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  40% 3.95G/9.99G [00:39<00:50, 121MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  39% 3.87G/9.97G [00:39<00:49, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  69% 4.02G/5.79G [00:39<00:14, 119MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  40% 3.97G/9.99G [00:39<00:46, 129MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  39% 3.89G/9.97G [00:39<00:44, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  70% 4.05G/5.79G [00:39<00:12, 144MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  40% 4.01G/9.99G [00:39<00:40, 147MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  39% 3.92G/9.97G [00:39<00:40, 150MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  70% 4.07G/5.79G [00:40<00:12, 143MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  40% 4.03G/9.99G [00:40<00:37, 158MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  40% 3.95G/9.97G [00:39<00:34, 177MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  71% 4.11G/5.79G [00:40<00:08, 192MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  41% 4.07G/9.99G [00:40<00:28, 211MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  40% 4.00G/9.97G [00:40<00:28, 207MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  72% 4.14G/5.79G [00:40<00:08, 195MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  41% 4.10G/9.99G [00:40<00:30, 193MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  72% 4.16G/5.79G [00:40<00:10, 159MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  40% 4.03G/9.97G [00:40<00:35, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  41% 4.13G/9.99G [00:40<00:37, 155MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  72% 4.18G/5.79G [00:40<00:11, 141MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  41% 4.05G/9.97G [00:40<00:39, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  42% 4.15G/9.99G [00:40<00:42, 137MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  41% 4.07G/9.97G [00:40<00:43, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  73% 4.20G/5.79G [00:41<00:12, 125MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  42% 4.17G/9.99G [00:41<00:44, 131MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  41% 4.09G/9.97G [00:40<00:45, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  73% 4.23G/5.79G [00:41<00:12, 122MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  42% 4.19G/9.99G [00:41<00:47, 121MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  73% 4.25G/5.79G [00:41<00:13, 116MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  41% 4.11G/9.97G [00:41<00:50, 116MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  42% 4.22G/9.99G [00:41<00:49, 117MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  74% 4.27G/5.79G [00:41<00:13, 111MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  41% 4.13G/9.97G [00:41<00:51, 113MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  42% 4.24G/9.99G [00:41<00:52, 109MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  42% 4.15G/9.97G [00:41<00:51, 113MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  74% 4.29G/5.79G [00:41<00:13, 109MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  43% 4.26G/9.99G [00:41<00:53, 108MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  74% 4.31G/5.79G [00:42<00:13, 111MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  42% 4.17G/9.97G [00:41<00:52, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  43% 4.28G/9.99G [00:42<00:54, 105MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  75% 4.33G/5.79G [00:42<00:13, 109MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  42% 4.19G/9.97G [00:41<00:52, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  43% 4.30G/9.99G [00:42<00:53, 107MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  75% 4.35G/5.79G [00:42<00:13, 110MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  42% 4.22G/9.97G [00:42<00:52, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  43% 4.32G/9.99G [00:42<00:54, 104MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  76% 4.37G/5.79G [00:42<00:14, 101MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  42% 4.24G/9.97G [00:42<00:56, 101MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  76% 4.38G/5.79G [00:42<00:15, 90.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  43% 4.25G/9.97G [00:42<01:04, 89.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  43% 4.34G/9.99G [00:42<01:06, 85.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  76% 4.39G/5.79G [00:43<00:17, 78.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  43% 4.26G/9.97G [00:42<01:16, 74.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  44% 4.35G/9.99G [00:43<01:20, 70.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  76% 4.40G/5.79G [00:43<00:21, 63.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  43% 4.27G/9.97G [00:43<01:28, 64.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  44% 4.36G/9.99G [00:43<01:17, 72.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  76% 4.42G/5.79G [00:43<00:16, 83.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  43% 4.29G/9.97G [00:43<01:07, 84.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  44% 4.38G/9.99G [00:43<01:01, 91.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  77% 4.45G/5.79G [00:43<00:13, 100MB/s] \u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  43% 4.31G/9.97G [00:43<00:55, 102MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  44% 4.40G/9.99G [00:43<00:52, 106MB/s] \u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  77% 4.47G/5.79G [00:43<00:11, 113MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  43% 4.33G/9.97G [00:43<00:48, 115MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  44% 4.42G/9.99G [00:43<00:46, 119MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  78% 4.50G/5.79G [00:43<00:08, 149MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  44% 4.36G/9.97G [00:43<00:37, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  45% 4.46G/9.99G [00:43<00:36, 151MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  78% 4.52G/5.79G [00:43<00:09, 138MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  44% 4.38G/9.97G [00:43<00:43, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  45% 4.48G/9.99G [00:43<00:41, 133MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  78% 4.54G/5.79G [00:44<00:10, 120MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  44% 4.40G/9.97G [00:43<00:47, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  45% 4.50G/9.99G [00:44<00:46, 117MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  79% 4.56G/5.79G [00:44<00:10, 121MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  44% 4.42G/9.97G [00:44<00:47, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  45% 4.52G/9.99G [00:44<00:46, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.45G/9.97G [00:44<00:50, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  79% 4.58G/5.79G [00:44<00:11, 103MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  45% 4.54G/9.99G [00:44<00:52, 105MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  80% 4.60G/5.79G [00:44<00:11, 104MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.47G/9.97G [00:44<00:52, 104MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  46% 4.56G/9.99G [00:44<00:54, 99.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.49G/9.97G [00:44<00:54, 99.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  80% 4.62G/5.79G [00:45<00:12, 95.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  46% 4.58G/9.99G [00:45<00:59, 91.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.50G/9.97G [00:44<00:56, 96.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  80% 4.63G/5.79G [00:45<00:12, 93.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  46% 4.59G/9.99G [00:45<01:00, 89.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  80% 4.65G/5.79G [00:45<00:12, 90.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.51G/9.97G [00:45<01:02, 87.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  46% 4.60G/9.99G [00:45<01:02, 86.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.52G/9.97G [00:45<01:04, 84.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  80% 4.66G/5.79G [00:45<00:13, 81.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  46% 4.61G/9.99G [00:45<01:04, 83.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.53G/9.97G [00:45<01:06, 82.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  81% 4.67G/5.79G [00:45<00:14, 79.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  46% 4.62G/9.99G [00:45<01:10, 76.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.54G/9.97G [00:45<01:08, 79.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  81% 4.68G/5.79G [00:45<00:14, 77.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  46% 4.63G/9.99G [00:45<01:11, 74.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  81% 4.69G/5.79G [00:45<00:14, 75.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.55G/9.97G [00:45<01:14, 73.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.65G/9.99G [00:45<01:07, 78.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.56G/9.97G [00:45<01:10, 77.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  81% 4.70G/5.79G [00:46<00:14, 75.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.66G/9.99G [00:46<01:05, 81.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.57G/9.97G [00:45<01:07, 79.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  81% 4.71G/5.79G [00:46<00:13, 78.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.67G/9.99G [00:46<01:08, 77.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.58G/9.97G [00:46<01:06, 81.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  82% 4.72G/5.79G [00:46<00:13, 80.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.68G/9.99G [00:46<01:07, 79.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  82% 4.73G/5.79G [00:46<00:13, 80.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.59G/9.97G [00:46<01:10, 76.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.69G/9.99G [00:46<01:06, 79.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  82% 4.74G/5.79G [00:46<00:13, 80.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.60G/9.97G [00:46<01:09, 76.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.70G/9.99G [00:46<01:07, 78.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.61G/9.97G [00:46<01:10, 76.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  82% 4.75G/5.79G [00:46<00:14, 73.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.71G/9.99G [00:46<01:09, 76.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  82% 4.76G/5.79G [00:46<00:14, 72.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.62G/9.97G [00:46<01:16, 70.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.72G/9.99G [00:46<01:15, 69.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.63G/9.97G [00:46<01:16, 70.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  82% 4.77G/5.79G [00:47<00:15, 67.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.73G/9.99G [00:47<01:17, 67.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  83% 4.78G/5.79G [00:47<00:15, 66.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  47% 4.65G/9.97G [00:47<01:22, 64.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.74G/9.99G [00:47<01:24, 62.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  47% 4.66G/9.97G [00:47<01:25, 62.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  83% 4.79G/5.79G [00:47<00:16, 60.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  48% 4.75G/9.99G [00:47<01:27, 60.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  83% 4.80G/5.79G [00:47<00:16, 60.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  47% 4.67G/9.97G [00:47<01:30, 58.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  48% 4.76G/9.99G [00:47<01:23, 62.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  47% 4.68G/9.97G [00:47<01:21, 65.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  83% 4.81G/5.79G [00:47<00:15, 64.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  48% 4.77G/9.99G [00:47<01:14, 70.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  47% 4.69G/9.97G [00:47<01:13, 72.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  48% 4.78G/9.99G [00:47<01:08, 75.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  83% 4.83G/5.79G [00:48<00:11, 80.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  47% 4.72G/9.97G [00:47<00:43, 121MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  48% 4.81G/9.99G [00:47<00:39, 131MB/s] \u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  84% 4.87G/5.79G [00:48<00:07, 121MB/s] \u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  48% 4.76G/9.97G [00:47<00:30, 172MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  49% 4.84G/9.99G [00:48<00:33, 153MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  84% 4.89G/5.79G [00:48<00:06, 133MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  48% 4.78G/9.97G [00:48<00:31, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  85% 4.92G/5.79G [00:48<00:05, 174MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  49% 4.87G/9.99G [00:48<00:33, 155MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  48% 4.81G/9.97G [00:48<00:27, 190MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  85% 4.95G/5.79G [00:48<00:04, 196MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  49% 4.90G/9.99G [00:48<00:26, 193MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  49% 4.84G/9.97G [00:48<00:23, 215MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  86% 4.98G/5.79G [00:48<00:03, 225MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  49% 4.93G/9.99G [00:48<00:22, 221MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  49% 4.88G/9.97G [00:48<00:27, 184MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  50% 4.96G/9.99G [00:48<00:27, 182MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  87% 5.01G/5.79G [00:48<00:04, 177MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  49% 4.90G/9.97G [00:48<00:32, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  50% 4.98G/9.99G [00:48<00:32, 152MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  87% 5.03G/5.79G [00:49<00:05, 148MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  49% 4.92G/9.97G [00:48<00:35, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  50% 5.00G/9.99G [00:49<00:35, 140MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  87% 5.05G/5.79G [00:49<00:05, 130MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  50% 5.02G/9.99G [00:49<00:37, 131MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  88% 5.08G/5.79G [00:49<00:05, 127MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  50% 4.94G/9.97G [00:49<00:49, 103MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  51% 5.04G/9.99G [00:49<00:36, 136MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  88% 5.10G/5.79G [00:49<00:05, 130MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  50% 4.96G/9.97G [00:49<00:47, 106MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  88% 5.12G/5.79G [00:49<00:05, 125MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  51% 5.06G/9.99G [00:49<00:43, 114MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  50% 4.98G/9.97G [00:49<00:45, 109MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  89% 5.14G/5.79G [00:49<00:05, 119MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  51% 5.09G/9.99G [00:49<00:42, 115MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  50% 5.00G/9.97G [00:51<03:01, 27.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  89% 5.16G/5.79G [00:52<00:22, 28.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  51% 5.11G/9.99G [00:52<02:54, 27.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  51% 5.04G/9.97G [00:51<01:44, 47.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  90% 5.20G/5.79G [00:52<00:12, 49.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  52% 5.16G/9.99G [00:52<01:30, 53.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  51% 5.09G/9.97G [00:52<01:07, 72.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  91% 5.24G/5.79G [00:52<00:07, 74.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  52% 5.20G/9.99G [00:52<01:00, 78.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  51% 5.13G/9.97G [00:52<00:47, 103MB/s] \u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  91% 5.30G/5.79G [00:52<00:04, 114MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  53% 5.25G/9.99G [00:52<00:40, 116MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  52% 5.18G/9.97G [00:52<00:34, 140MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  53% 5.28G/9.99G [00:52<00:34, 136MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  92% 5.34G/5.79G [00:52<00:03, 139MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  52% 5.21G/9.97G [00:52<00:34, 138MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  53% 5.32G/9.99G [00:52<00:35, 131MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  93% 5.37G/5.79G [00:52<00:03, 134MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  53% 5.24G/9.97G [00:52<00:37, 127MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.35G/9.99G [00:53<00:38, 121MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  93% 5.40G/5.79G [00:53<00:03, 123MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.37G/9.99G [00:53<00:39, 117MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  94% 5.42G/5.79G [00:53<00:03, 118MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  53% 5.27G/9.97G [00:53<00:39, 119MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.39G/9.99G [00:53<00:38, 118MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  94% 5.44G/5.79G [00:53<00:02, 118MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  53% 5.30G/9.97G [00:53<00:38, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.41G/9.99G [00:53<00:37, 122MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  94% 5.46G/5.79G [00:53<00:02, 123MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  53% 5.32G/9.97G [00:53<00:37, 126MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.43G/9.99G [00:53<00:35, 129MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  95% 5.48G/5.79G [00:53<00:02, 130MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  54% 5.34G/9.97G [00:53<00:36, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  55% 5.45G/9.99G [00:53<00:34, 130MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  95% 5.51G/5.79G [00:53<00:02, 130MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  54% 5.36G/9.97G [00:53<00:35, 130MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  55% 5.47G/9.99G [00:53<00:32, 139MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  95% 5.53G/5.79G [00:54<00:01, 141MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  54% 5.39G/9.97G [00:53<00:28, 158MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  55% 5.52G/9.99G [00:54<00:23, 188MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  96% 5.57G/5.79G [00:54<00:01, 186MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  54% 5.42G/9.97G [00:53<00:24, 189MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  56% 5.55G/9.99G [00:54<00:22, 196MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  97% 5.60G/5.79G [00:54<00:00, 191MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  55% 5.45G/9.97G [00:54<00:25, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  97% 5.62G/5.79G [00:54<00:01, 166MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  55% 5.47G/9.97G [00:54<00:29, 150MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  56% 5.58G/9.99G [00:54<00:28, 155MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  97% 5.64G/5.79G [00:54<00:01, 147MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  55% 5.49G/9.97G [00:54<00:32, 138MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  56% 5.60G/9.99G [00:54<00:31, 140MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  98% 5.66G/5.79G [00:54<00:00, 131MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  56% 5.62G/9.99G [00:54<00:32, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  55% 5.52G/9.97G [00:54<00:37, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  98% 5.68G/5.79G [00:55<00:00, 117MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  56% 5.64G/9.99G [00:55<00:36, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  56% 5.54G/9.97G [00:55<00:39, 113MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  99% 5.70G/5.79G [00:55<00:00, 115MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  57% 5.66G/9.99G [00:55<00:35, 121MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  56% 5.56G/9.97G [00:55<00:37, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  99% 5.73G/5.79G [00:55<00:00, 116MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  57% 5.68G/9.99G [00:55<00:37, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  56% 5.58G/9.97G [00:55<00:38, 113MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  99% 5.75G/5.79G [00:55<00:00, 113MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  56% 5.60G/9.97G [00:55<00:38, 115MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  57% 5.70G/9.99G [00:55<00:39, 109MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors: 100% 5.77G/5.79G [00:55<00:00, 109MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  56% 5.62G/9.97G [00:55<00:39, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  57% 5.73G/9.99G [00:55<00:40, 107MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00003-of-00003.safetensors: 100% 5.79G/5.79G [00:58<00:00, 99.3MB/s]\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  57% 5.64G/9.97G [00:58<02:46, 25.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  57% 5.69G/9.97G [00:58<01:24, 50.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  58% 5.75G/9.99G [00:58<02:53, 24.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  58% 5.75G/9.97G [00:58<00:51, 81.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  58% 5.80G/9.99G [00:58<01:28, 47.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  58% 5.80G/9.97G [00:58<00:35, 117MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  59% 5.85G/9.99G [00:58<00:54, 75.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  59% 5.85G/9.97G [00:58<00:26, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  59% 5.90G/9.99G [00:58<00:37, 110MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  59% 5.90G/9.97G [00:58<00:20, 198MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  60% 5.95G/9.99G [00:58<00:28, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  60% 5.95G/9.97G [00:58<00:17, 226MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  60% 6.00G/9.99G [00:59<00:21, 183MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  60% 5.99G/9.97G [00:58<00:15, 257MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  60% 6.03G/9.97G [00:58<00:13, 289MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  61% 6.05G/9.99G [00:59<00:17, 226MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  61% 6.07G/9.97G [00:59<00:14, 267MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  61% 6.09G/9.99G [00:59<00:17, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  61% 6.11G/9.97G [00:59<00:14, 266MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  61% 6.13G/9.99G [00:59<00:16, 228MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  62% 6.17G/9.99G [00:59<00:17, 216MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  62% 6.16G/9.97G [00:59<00:16, 228MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  62% 6.20G/9.99G [00:59<00:18, 202MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  62% 6.19G/9.97G [00:59<00:17, 221MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  62% 6.24G/9.99G [00:59<00:16, 234MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  62% 6.23G/9.97G [00:59<00:15, 249MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  63% 6.29G/9.99G [01:00<00:12, 284MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  63% 6.27G/9.97G [00:59<00:13, 283MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  64% 6.34G/9.99G [01:00<00:11, 313MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  63% 6.32G/9.97G [01:00<00:12, 298MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  64% 6.39G/9.99G [01:00<00:15, 233MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  64% 6.36G/9.97G [01:00<00:16, 214MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  64% 6.42G/9.99G [01:00<00:15, 223MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  64% 6.40G/9.97G [01:00<00:17, 208MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  65% 6.45G/9.99G [01:00<00:16, 220MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  64% 6.43G/9.97G [01:00<00:18, 192MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  65% 6.48G/9.99G [01:01<00:17, 196MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  65% 6.46G/9.97G [01:01<00:19, 176MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  65% 6.51G/9.99G [01:01<00:18, 192MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  65% 6.48G/9.97G [01:01<00:20, 170MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  65% 6.53G/9.99G [01:01<00:18, 183MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  65% 6.50G/9.97G [01:01<00:21, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  66% 6.55G/9.99G [01:01<00:19, 174MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  65% 6.52G/9.97G [01:01<00:21, 163MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  66% 6.57G/9.99G [01:01<00:21, 162MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  66% 6.55G/9.97G [01:01<00:20, 169MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  66% 6.60G/9.99G [01:01<00:20, 163MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  66% 6.57G/9.97G [01:01<00:20, 170MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  66% 6.62G/9.99G [01:01<00:21, 156MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  66% 6.60G/9.97G [01:01<00:20, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  66% 6.64G/9.99G [01:02<00:20, 161MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  66% 6.62G/9.97G [01:01<00:20, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  67% 6.66G/9.99G [01:02<00:20, 161MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  67% 6.64G/9.97G [01:02<00:20, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  67% 6.68G/9.99G [01:02<00:20, 163MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  67% 6.66G/9.97G [01:02<00:21, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  67% 6.70G/9.99G [01:02<00:20, 159MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  67% 6.68G/9.97G [01:02<00:20, 163MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  67% 6.72G/9.99G [01:02<00:20, 157MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  68% 6.74G/9.99G [01:02<00:21, 150MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  67% 6.70G/9.97G [01:02<00:27, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  68% 6.76G/9.99G [01:02<00:22, 140MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  67% 6.72G/9.97G [01:02<00:25, 127MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  68% 6.78G/9.99G [01:03<00:23, 134MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  68% 6.74G/9.97G [01:02<00:26, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  68% 6.81G/9.99G [01:03<00:24, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  68% 6.76G/9.97G [01:03<00:26, 121MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  68% 6.83G/9.99G [01:03<00:25, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  68% 6.78G/9.97G [01:03<00:26, 119MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  69% 6.85G/9.99G [01:03<00:25, 121MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  68% 6.81G/9.97G [01:03<00:26, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  69% 6.87G/9.99G [01:03<00:26, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  68% 6.83G/9.97G [01:03<00:26, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  69% 6.89G/9.99G [01:03<00:26, 117MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  69% 6.85G/9.97G [01:03<00:26, 116MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  69% 6.91G/9.99G [01:04<00:26, 118MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  69% 6.87G/9.97G [01:04<00:26, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  69% 6.93G/9.99G [01:04<00:25, 119MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  69% 6.89G/9.97G [01:04<00:25, 119MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  70% 6.95G/9.99G [01:04<00:25, 120MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  69% 6.91G/9.97G [01:04<00:25, 121MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  70% 6.97G/9.99G [01:04<00:24, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  70% 6.93G/9.97G [01:04<00:22, 135MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  70% 7.03G/9.99G [01:04<00:15, 197MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  70% 6.97G/9.97G [01:04<00:15, 191MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  71% 7.08G/9.99G [01:04<00:11, 258MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  70% 7.03G/9.97G [01:04<00:11, 254MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  71% 7.06G/9.97G [01:04<00:11, 252MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  71% 7.13G/9.99G [01:05<00:10, 280MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  71% 7.09G/9.97G [01:05<00:13, 221MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  72% 7.16G/9.99G [01:05<00:12, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  71% 7.12G/9.97G [01:05<00:14, 197MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  72% 7.19G/9.99G [01:05<00:13, 203MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  72% 7.15G/9.97G [01:05<00:15, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  72% 7.22G/9.99G [01:05<00:14, 194MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  72% 7.17G/9.97G [01:05<00:16, 174MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  73% 7.25G/9.99G [01:05<00:14, 184MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  72% 7.19G/9.97G [01:05<00:16, 172MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  73% 7.27G/9.99G [01:05<00:15, 175MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  72% 7.21G/9.97G [01:05<00:16, 166MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  73% 7.29G/9.99G [01:06<00:15, 171MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  73% 7.24G/9.97G [01:06<00:16, 166MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  73% 7.31G/9.99G [01:06<00:15, 169MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  73% 7.26G/9.97G [01:06<00:16, 163MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  73% 7.33G/9.99G [01:06<00:16, 164MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  73% 7.28G/9.97G [01:06<00:16, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  74% 7.35G/9.99G [01:06<00:16, 163MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  73% 7.30G/9.97G [01:06<00:16, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  74% 7.37G/9.99G [01:06<00:16, 162MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  73% 7.32G/9.97G [01:07<00:33, 79.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  74% 7.39G/9.99G [01:08<01:02, 41.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  74% 7.34G/9.97G [01:08<01:22, 32.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  74% 7.40G/9.97G [01:08<00:37, 67.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  74% 7.41G/9.99G [01:08<01:17, 33.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  75% 7.44G/9.97G [01:08<00:26, 93.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  75% 7.47G/9.99G [01:09<00:39, 63.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  75% 7.49G/9.97G [01:08<00:19, 125MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  75% 7.52G/9.99G [01:09<00:24, 99.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  75% 7.53G/9.97G [01:09<00:15, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  76% 7.57G/9.99G [01:09<00:17, 141MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  76% 7.57G/9.97G [01:09<00:12, 196MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  76% 7.62G/9.99G [01:09<00:12, 186MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  76% 7.61G/9.97G [01:09<00:10, 233MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  77% 7.68G/9.99G [01:09<00:09, 236MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  77% 7.67G/9.97G [01:09<00:08, 284MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  77% 7.73G/9.99G [01:09<00:07, 284MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  77% 7.72G/9.97G [01:09<00:06, 332MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  78% 7.78G/9.99G [01:09<00:06, 326MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  78% 7.77G/9.97G [01:09<00:05, 372MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  78% 7.83G/9.99G [01:09<00:06, 351MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  78% 7.82G/9.97G [01:09<00:05, 389MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  79% 7.89G/9.99G [01:10<00:06, 332MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  79% 7.87G/9.97G [01:09<00:06, 322MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  79% 7.93G/9.99G [01:10<00:07, 264MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  79% 7.92G/9.97G [01:10<00:08, 248MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  80% 7.97G/9.99G [01:10<00:08, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  80% 7.95G/9.97G [01:10<00:09, 215MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  80% 8.00G/9.99G [01:10<00:09, 210MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  80% 7.98G/9.97G [01:10<00:09, 200MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  80% 8.03G/9.99G [01:12<00:29, 67.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  80% 8.01G/9.97G [01:12<00:37, 52.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  81% 8.05G/9.99G [01:12<00:36, 52.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  81% 8.08G/9.99G [01:13<00:28, 67.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  81% 8.03G/9.97G [01:13<00:39, 49.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  81% 8.14G/9.99G [01:13<00:17, 104MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  81% 8.07G/9.97G [01:13<00:26, 72.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  82% 8.19G/9.99G [01:13<00:12, 145MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  81% 8.12G/9.97G [01:13<00:18, 101MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  83% 8.24G/9.99G [01:13<00:09, 190MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  82% 8.16G/9.97G [01:13<00:13, 132MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  83% 8.29G/9.99G [01:13<00:07, 238MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  84% 8.36G/9.99G [01:13<00:05, 298MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  82% 8.19G/9.97G [01:13<00:12, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  84% 8.41G/9.99G [01:13<00:04, 322MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  83% 8.24G/9.97G [01:13<00:09, 192MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  85% 8.46G/9.99G [01:13<00:04, 357MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  83% 8.28G/9.97G [01:13<00:07, 226MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  83% 8.33G/9.97G [01:13<00:06, 237MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  85% 8.51G/9.99G [01:14<00:04, 338MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  84% 8.37G/9.97G [01:14<00:06, 236MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  86% 8.56G/9.99G [01:14<00:04, 303MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  84% 8.40G/9.97G [01:14<00:06, 231MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  86% 8.60G/9.99G [01:14<00:05, 271MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  85% 8.43G/9.97G [01:14<00:07, 218MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  86% 8.63G/9.99G [01:14<00:05, 248MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  85% 8.46G/9.97G [01:14<00:07, 216MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  87% 8.66G/9.99G [01:14<00:05, 234MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  85% 8.49G/9.97G [01:14<00:07, 207MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  87% 8.69G/9.99G [01:14<00:05, 223MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  85% 8.52G/9.97G [01:14<00:07, 199MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  87% 8.72G/9.99G [01:15<00:06, 204MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  86% 8.55G/9.97G [01:15<00:07, 191MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  86% 8.57G/9.97G [01:15<00:07, 182MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  88% 8.76G/9.99G [01:15<00:06, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  86% 8.59G/9.97G [01:15<00:08, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  88% 8.78G/9.99G [01:15<00:06, 176MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  86% 8.61G/9.97G [01:15<00:08, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  88% 8.80G/9.99G [01:15<00:07, 164MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  87% 8.63G/9.97G [01:15<00:09, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  88% 8.82G/9.99G [01:15<00:07, 147MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  87% 8.65G/9.97G [01:15<00:10, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  89% 8.84G/9.99G [01:16<00:08, 128MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  87% 8.67G/9.97G [01:16<00:11, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  89% 8.86G/9.99G [01:16<00:09, 113MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  87% 8.69G/9.97G [01:16<00:11, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  89% 8.88G/9.99G [01:16<00:09, 115MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  87% 8.71G/9.97G [01:16<00:10, 121MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  89% 8.90G/9.99G [01:16<00:08, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  88% 8.73G/9.97G [01:16<00:09, 132MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  89% 8.92G/9.99G [01:16<00:07, 135MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  88% 8.76G/9.97G [01:16<00:08, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  90% 8.94G/9.99G [01:17<00:16, 64.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  88% 8.78G/9.97G [01:19<00:46, 26.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  90% 8.97G/9.99G [01:19<00:36, 28.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  88% 8.82G/9.97G [01:19<00:25, 45.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  90% 9.01G/9.99G [01:19<00:20, 48.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  91% 9.05G/9.99G [01:19<00:12, 74.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  89% 8.87G/9.97G [01:19<00:14, 75.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  89% 8.91G/9.97G [01:19<00:10, 105MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  91% 9.09G/9.99G [01:19<00:08, 104MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  90% 8.94G/9.97G [01:19<00:09, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  91% 9.12G/9.99G [01:19<00:07, 108MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  90% 8.98G/9.97G [01:19<00:08, 121MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  92% 9.15G/9.99G [01:19<00:06, 123MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  90% 9.02G/9.97G [01:19<00:05, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  92% 9.20G/9.99G [01:20<00:05, 157MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  91% 9.05G/9.97G [01:20<00:06, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  92% 9.23G/9.99G [01:20<00:04, 155MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  91% 9.08G/9.97G [01:20<00:05, 156MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  93% 9.26G/9.99G [01:20<00:04, 152MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  93% 9.28G/9.99G [01:20<00:04, 147MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  91% 9.11G/9.97G [01:20<00:05, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  93% 9.31G/9.99G [01:20<00:03, 170MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  92% 9.14G/9.97G [01:20<00:04, 171MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  93% 9.33G/9.99G [01:20<00:03, 169MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  92% 9.16G/9.97G [01:20<00:04, 166MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  94% 9.35G/9.99G [01:21<00:04, 158MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  92% 9.19G/9.97G [01:20<00:04, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  94% 9.37G/9.99G [01:21<00:04, 146MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  92% 9.21G/9.97G [01:21<00:05, 142MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  94% 9.40G/9.99G [01:21<00:06, 97.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  93% 9.23G/9.97G [01:21<00:08, 91.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  94% 9.42G/9.99G [01:22<00:09, 58.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  93% 9.25G/9.97G [01:22<00:13, 54.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  94% 9.43G/9.99G [01:22<00:12, 44.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  93% 9.26G/9.97G [01:22<00:16, 44.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  94% 9.44G/9.99G [01:23<00:14, 38.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  95% 9.46G/9.99G [01:23<00:09, 53.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  95% 9.48G/9.99G [01:23<00:07, 70.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  93% 9.27G/9.97G [01:23<00:20, 35.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  95% 9.52G/9.99G [01:23<00:03, 117MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  93% 9.32G/9.97G [01:23<00:08, 74.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  96% 9.57G/9.99G [01:23<00:02, 177MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  94% 9.37G/9.97G [01:23<00:05, 119MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  96% 9.63G/9.99G [01:23<00:01, 234MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  95% 9.43G/9.97G [01:23<00:03, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  97% 9.68G/9.99G [01:24<00:01, 287MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  95% 9.47G/9.97G [01:23<00:02, 199MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  97% 9.73G/9.99G [01:24<00:00, 325MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  95% 9.51G/9.97G [01:24<00:01, 237MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  98% 9.77G/9.99G [01:24<00:00, 263MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  96% 9.55G/9.97G [01:24<00:02, 191MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  98% 9.81G/9.99G [01:24<00:00, 197MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  96% 9.58G/9.97G [01:24<00:02, 170MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  99% 9.85G/9.99G [01:24<00:00, 214MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  97% 9.63G/9.97G [01:24<00:01, 205MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  99% 9.89G/9.99G [01:25<00:00, 109MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  97% 9.67G/9.97G [01:29<00:11, 25.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  99% 9.91G/9.99G [01:30<00:03, 20.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  97% 9.69G/9.97G [01:30<00:11, 25.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors: 100% 9.96G/9.99G [01:30<00:00, 32.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  98% 9.74G/9.97G [01:30<00:05, 40.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors: 100% 9.99G/9.99G [01:30<00:00, 110MB/s] \n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  98% 9.77G/9.97G [01:30<00:03, 50.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  98% 9.80G/9.97G [01:30<00:02, 63.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  99% 9.86G/9.97G [01:30<00:01, 90.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  99% 9.91G/9.97G [01:31<00:00, 124MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors: 100% 9.97G/9.97G [01:31<00:00, 109MB/s]\n",
            "Fetching 3 files: 100% 3/3 [01:31<00:00, 30.64s/it]\n",
            "Loading checkpoint shards: 100% 3/3 [00:00<00:00,  5.59it/s]\n",
            "transformer.high_quality_fp32_output_for_inference = True\n",
            "* Running on local URL:  http://0.0.0.0:7860\n",
            "* Running on public URL: https://4604c31234853f7fb8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\n",
            "Unloaded CLIPTextModel as complete.\n",
            "Unloaded SiglipVisionModel as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Unloaded DynamicSwap_HunyuanVideoTransformer3DModelPacked as complete.\n",
            "Loaded CLIPTextModel to cuda:0 as complete.\n",
            "Unloaded CLIPTextModel as complete.\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Loaded SiglipVisionModel to cuda:0 as complete.\n",
            "latent_padding_size = 27, is_last_section = False\n",
            "Unloaded SiglipVisionModel as complete.\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [06:20<00:00, 15.22s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 9, 104, 60]); pixel shape torch.Size([1, 3, 33, 832, 480])\n",
            "latent_padding_size = 18, is_last_section = False\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:39<00:00, 13.59s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 18, 104, 60]); pixel shape torch.Size([1, 3, 69, 832, 480])\n",
            "latent_padding_size = 9, is_last_section = False\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:39<00:00, 13.60s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 27, 104, 60]); pixel shape torch.Size([1, 3, 105, 832, 480])\n",
            "latent_padding_size = 0, is_last_section = True\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:39<00:00, 13.60s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 37, 104, 60]); pixel shape torch.Size([1, 3, 145, 832, 480])\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\n",
            "Unloaded CLIPTextModel as complete.\n",
            "Unloaded SiglipVisionModel as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Unloaded DynamicSwap_HunyuanVideoTransformer3DModelPacked as complete.\n",
            "Loaded CLIPTextModel to cuda:0 as complete.\n",
            "Unloaded CLIPTextModel as complete.\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Loaded SiglipVisionModel to cuda:0 as complete.\n",
            "latent_padding_size = 27, is_last_section = False\n",
            "Unloaded SiglipVisionModel as complete.\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:40<00:00, 13.61s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 9, 88, 68]); pixel shape torch.Size([1, 3, 33, 704, 544])\n",
            "latent_padding_size = 18, is_last_section = False\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:24<00:00, 12.97s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 18, 88, 68]); pixel shape torch.Size([1, 3, 69, 704, 544])\n",
            "latent_padding_size = 18, is_last_section = False\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:24<00:00, 12.97s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 27, 88, 68]); pixel shape torch.Size([1, 3, 105, 704, 544])\n",
            "latent_padding_size = 18, is_last_section = False\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:24<00:00, 12.98s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 36, 88, 68]); pixel shape torch.Size([1, 3, 141, 704, 544])\n",
            "latent_padding_size = 18, is_last_section = False\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:24<00:00, 12.98s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 45, 88, 68]); pixel shape torch.Size([1, 3, 177, 704, 544])\n",
            "latent_padding_size = 18, is_last_section = False\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:24<00:00, 12.98s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 54, 88, 68]); pixel shape torch.Size([1, 3, 213, 704, 544])\n",
            "latent_padding_size = 18, is_last_section = False\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:24<00:00, 12.97s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 63, 88, 68]); pixel shape torch.Size([1, 3, 249, 704, 544])\n",
            "latent_padding_size = 18, is_last_section = False\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:24<00:00, 12.98s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 72, 88, 68]); pixel shape torch.Size([1, 3, 285, 704, 544])\n",
            "latent_padding_size = 18, is_last_section = False\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:24<00:00, 12.97s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 81, 88, 68]); pixel shape torch.Size([1, 3, 321, 704, 544])\n",
            "latent_padding_size = 18, is_last_section = False\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:24<00:00, 12.97s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 90, 88, 68]); pixel shape torch.Size([1, 3, 357, 704, 544])\n",
            "latent_padding_size = 9, is_last_section = False\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:24<00:00, 12.97s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 99, 88, 68]); pixel shape torch.Size([1, 3, 393, 704, 544])\n",
            "latent_padding_size = 0, is_last_section = True\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\n",
            "100% 25/25 [05:24<00:00, 12.97s/it]\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Decoded. Current latent shape torch.Size([1, 16, 109, 88, 68]); pixel shape torch.Size([1, 3, 433, 704, 544])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/FramePack-Colab/demo_gradio.py\", line 319, in worker\n",
            "    drive.mount('/content/drive')\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\", line 100, in mount\n",
            "    return _mount(\n",
            "           ^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\", line 137, in _mount\n",
            "    _message.blocking_request(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\", line 173, in blocking_request\n",
            "    request_id = send_request(\n",
            "                 ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\", line 117, in send_request\n",
            "    instance = ipython.get_kernelapp()\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_ipython.py\", line 28, in get_kernelapp\n",
            "    return get_ipython().kernel.parent\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'kernel'\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\n",
            "Unloaded CLIPTextModel as complete.\n",
            "Unloaded SiglipVisionModel as complete.\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\n",
            "Unloaded DynamicSwap_HunyuanVideoTransformer3DModelPacked as complete.\n",
            "Job completed. Disconnecting and deleting runtime...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 715, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2137, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1675, in call_function\n",
            "    prediction = await utils.async_iteration(iterator)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 735, in async_iteration\n",
            "    return await anext(iterator)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 729, in __anext__\n",
            "    return await anyio.to_thread.run_sync(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 2476, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 712, in run_sync_iterator_async\n",
            "    return next(iterator)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 873, in gen_wrapper\n",
            "    response = next(iterator)\n",
            "               ^^^^^^^^^^^^^^\n",
            "  File \"/content/FramePack-Colab/demo_gradio.py\", line 367, in process\n",
            "    runtime.unassign()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/runtime.py\", line 38, in unassign\n",
            "    _output.eval_js('google.colab.kernel.disconnect();', ignore_result=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\", line 36, in eval_js\n",
            "    kernel = _ipython.get_kernel()\n",
            "             ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_ipython.py\", line 24, in get_kernel\n",
            "    return get_ipython().kernel\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'kernel'\n"
          ]
        }
      ]
    }
  ]
}